# python + flask + celery

## âœ”

## 01 base

- 1. redis ì„¤ì¹˜í•˜ê¸°
- 2. pip install celery, pip install redis ì„¤ì¹˜í•˜ê¸°

- 3.1 celeryconfig.py ì‘ì„±
- ì„¤ì • íŒŒì¼ì´ë‹¤.

- ë°”ë¡œ ì ‘ì†í•˜ê¸°
- 'redis://133.186.xxx.00:6379/0'

- ë¹„ë²ˆë§Œ ìˆëŠ” ê²½ìš°
- 'redis://:dosimpact@133.186.xxx.00:6379/0'

```py
broker_url = 'redis://:dosimpact@xxx.xxx.xxx.72:6379/0'
result_backend = 'redis://:dosimpact@xxx.xxx.xxx.72:6379/0'

task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
timezone = 'Asia/Seoul'
enable_utc = True

# # ì˜¤ì‘ë™ í•œ ì‘ì—…ì„ ì „ìš© ëŒ€ê¸°ì—´ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì„¤ì •
# task_routes = {
#     'tasks.add': 'low-priority'
# }

# # ì‘ì—… ì†ë„ë¥¼ ì œí•œí•˜ëŠ” ì„¤ì •
# task_annotations = {
#     'tasks.add': {'rate_limit': '10/m'
# }

```

- 3.2 processor.py ì‘ì„±
- ê¸´ ì‘ì—…ì´ ê±¸ë¦¬ëŠ” entry points
- window10 ì—ì„œëŠ” ì• ëŸ¬ê°€ ë‚˜ì„œ os.environ.setdefault('FORKED_BY_MULTIPROCESSING', '1') ì¶”ê°€

```py
# processor.py
from celery import Celery
import time
import os

# in window env Error, https://github.com/celery/celery/pull/4078
os.environ.setdefault('FORKED_BY_MULTIPROCESSING', '1')
# dosimpact
# BROKER_URL = 'redis://:dosimpact@133.186.xxx.00:6379/0'
# CELERY_RESULT_BACKEND = 'redis://dosimpact@133.186.xxx.00:6379/0'
celery = Celery('tasks')
celery.config_from_object('celeryconfig')


# celery -A processor worker --loglevel=info


@celery.task
def add( x, y):
    return x + y

```

- 3.3 ì‘ì—…ì„ ì£¼ëŠ” pub.py ì‘ì„±
- celeryì˜ ë°ì½”ë ˆì´í„°ê°€ ë¶™ì€ í•¨ìˆ˜ëŠ” delayë¥¼ ê°€ì§€ê³  ì´ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ì—… íì— ë„£ëŠ”ë‹¤.
- ë°˜í™˜ì€ resultAsync ê°ì²´ì´ê³ , ready()ë¥¼ í†µí•´ idê°€ ë°œê¸‰ë˜ê³ 
- idë¡œ ì‘ì—…ì—¬ë¶€ë¥¼ í™•ì¸ ê°€ëŠ¥

```py
from processor import add
from time import sleep
# task pub
for i in range(1):
    result = add.delay(1, 2)
    print(f"result : {result} {result.ready()}")
```

## 02 state check, event

ğŸš€ python + celery + redis MSA ìŠ¤íƒ

âœ” íì— ì‘ì—…ì„ ì£¼ê¸°  
âœ” íŠ¹ì • í idì˜ í˜„ì¬ì˜ ì‘ì—… ìƒíƒœëŠ” ?  
âœ” íŠ¹ì • í idì˜ ì‘ì—… ëë‚˜ë©´ ë§í•´ì¤˜ ( celery workers -> evernts )

---

- 1. redis ì„¤ì¹˜
- ë„ì»¤ë¥¼ í†µí•´ì„œ ì„¤ì¹˜ í–ˆë‹¤.
- passwordê°€ í¬í•¨ëœ urlëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
- 'redis://:dosimpact@133.186.xxx.00:6379/0'

- 2. pip install redis, pip install celery
- celery ëŠ” ì„¤ì¹˜ ê²½ë¡œì— exe íŒŒì¼ì´ ìˆë‹¤.

- 3. celeryconfig.py
- redisë¥¼ ë©”ì‹œì§€ ë¸Œë¡œì»¤ ë°±ì•¤ë“œë¡œ ì‚¬ìš©í•œë‹¤.

```py
broker_url = 'redis://:dosimpact@133.186.229.72:6379/0'
result_backend = 'redis://:dosimpact@133.186.229.72:6379/0'

task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
timezone = 'Asia/Seoul'
enable_utc = True

# # ì˜¤ì‘ë™ í•œ ì‘ì—…ì„ ì „ìš© ëŒ€ê¸°ì—´ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì„¤ì •
# task_routes = {
#     'tasks.add': 'low-priority'
# }

# # ì‘ì—… ì†ë„ë¥¼ ì œí•œí•˜ëŠ” ì„¤ì •
# task_annotations = {
#     'tasks.add': {'rate_limit': '10/m'
# }
```

- 4. processor.py
- ì‘ì—…íë¥¼ ë°›ëŠ” ì‹œì‘ì ì´ë‹¤.
- celery í´ë¼ì´ì–¸íŠ¸ë¼ê³ ë„ ë³¼ ìˆ˜ ìˆë‹¤.

```py
# processor.py
# from celery import Celery
import celery
from celery.events.snapshot import Polaroid
import time
import os
from pprint import pformat

# ìœˆë„ìš° í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ì…‹íŒ…ì„ í•´ì•¼ ì¸ìˆ˜ì „ë‹¬ì´ ì œëŒ€ë¡œ ëœë‹¤.
# in window env Error, https://github.com/celery/celery/pull/4078
os.environ.setdefault('FORKED_BY_MULTIPROCESSING', '1')


# celery ì„¤ì • ë° ì¸ìŠ¤í„´ìŠ¤
# BROKER_URL = 'redis://:dosimpact@133.186.229.72:6379/0'
# CELERY_RESULT_BACKEND = 'redis://dosimpact@133.186.229.72:6379/0'
process = celery.Celery('tasks')
process.config_from_object('celeryconfig')

# celery ì‹¤í–‰ ëª…ë ¹ì–´
# celery -A processor worker --loglevel=info
# ìµœì†Œ 3ê°œ ~ 10ê°œì˜ ì›Œì»¤ê°€ ì‘ë™
# celery -A processor worker --loglevel=info --autoscale=3,3


# celery ì´ë²¤íŠ¸ ì‹¤í–‰ì‹œ ê¸°ë³¸ í•¨ìˆ˜
# Event-driven


class CoreTask(celery.Task):
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        print(f'{task_id} on_failure: {exc}')

    def on_success(self, retval, task_id, args, kwargs):
        print(f'{task_id} on_success')

    def on_retry(self, exc, task_id, args, kwargs, einfo):
        print(f'{task_id} on_retry: {exc}')


# bind ì˜µì…˜ì„ í†µí•´ self, ë¥¼ ì‚¬ìš©
# base ì˜µì…˜ì„ í†µí•´ onEventë¥¼ ì²˜ë¦¬
@process.task(bind=True, base=CoreTask)
def add(self, x, y):
    total = 3
    for idx in range(total):
        time.sleep(1)
        print(f"progress ({idx}/{total})")
        # í˜„ì¬ ì‘ì—…ì¤‘ì¸ taskë¥¼ ì—…ë°ì´íŠ¸, update_state
        self.update_state(state='PROGRESS', meta={
                          'current': idx, 'total': total})

    # í˜„ì¬ ì‘ì—…ì¤‘ì¸ id
    print(f"done task {self.request.id}")
    return x + y

```

- 5. pub.py
- ì‘ì—…íë¥¼ ì£¼ëŠ” ê³³
- flaskì™€ ì—°ê²°ì´ ëœë‹¤.

```py
from processor import add
from time import sleep


# task pub
for i in range(1):
    result = add.apply_async([1, 2])
    print(f"result : {result} {result.ready()}")

# result = add.apply_async([(2, 2), (3, 3), (4, 4)])
# print(f"result : {result.ready()}")

```

- 6. state.py
- ì‘ì—…idë¥¼ í†µí•´ì„œ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ê´€ì°°

```py

from processor import add
from time import sleep


def get_progress(task_id: str):
    task = add.AsyncResult(task_id)
    print(task, task.state)
    if task.state == 'PENDING':
        response = {'state': task.state, 'current': 0, 'total': 1}
    elif task.state == "SUCCESS":
        response = {'state': task.state, 'current': 1, 'total': 1}
    elif task.state != 'FAILURE':
        response = {'state': task.state, 'current': task.info.get(
            'current', 0), 'total': task.info.get('total', 1)}
    return (response)


res = get_progress("ee900e77-896f-48d6-beb8-8b5d5633a2b2")
print(res)

```

### Ref

[https://core-research-team.github.io/2020-03-01/Celery-Flask-30e28a8974974f6cb55ed0c07d042671](https://core-research-team.github.io/2020-03-01/Celery-Flask-30e28a8974974f6cb55ed0c07d042671)

[https://heodolf.tistory.com/73](https://heodolf.tistory.com/73)

[https://docs.celeryproject.org/en/stable/userguide/tasks.html#task-result-backends](https://docs.celeryproject.org/en/stable/userguide/tasks.html#task-result-backends)

## 03 python + flask + celery

```

```
